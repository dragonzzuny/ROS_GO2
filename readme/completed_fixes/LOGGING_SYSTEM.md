# ğŸ“Š í¬ê´„ì  ë¡œê¹… ì‹œìŠ¤í…œ

**ëª©ì **: í•™ìŠµ ê³¼ì •ì˜ ëª¨ë“  ë°ì´í„°ë¥¼ ë¹ ì§ì—†ì´ ê¸°ë¡í•˜ì—¬ ë¬¸ì œ ì§„ë‹¨ ë° ì„±ëŠ¥ ë¶„ì„ ê°€ëŠ¥

**ì‘ì„±ì**: Reviewer ë°•ìš©ì¤€
**ì‘ì„±ì¼**: 2025-12-30

---

## ğŸ¯ ë¡œê¹… ì² í•™

> **"ì¸¡ì •í•  ìˆ˜ ì—†ìœ¼ë©´ ê°œì„ í•  ìˆ˜ ì—†ë‹¤"**

ëª¨ë“  í•™ìŠµ ë°ì´í„°ë¥¼ ë‹¤ìŒ 3ê°€ì§€ í˜•ì‹ìœ¼ë¡œ ì €ì¥:
1. **TensorBoard** - ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
2. **CSV** - ìƒì„¸ ë¶„ì„ ë° í”Œë¡¯
3. **JSON** - ì„¤ì • ë° ìµœì¢… ê²°ê³¼

---

## ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
runs/multi_map_logged/20251230-123456/
â”œâ”€â”€ tensorboard/              # TensorBoard ë¡œê·¸
â”‚   â””â”€â”€ events.out.tfevents.*
â”œâ”€â”€ csv/                      # CSV ë°ì´í„°
â”‚   â”œâ”€â”€ steps.csv            # Step-level ë°ì´í„°
â”‚   â”œâ”€â”€ episodes.csv         # Episode-level ë°ì´í„°
â”‚   â”œâ”€â”€ updates.csv          # Update-level ë°ì´í„°
â”‚   â”œâ”€â”€ map_large_square.csv # ë§µë³„ ë°ì´í„°
â”‚   â”œâ”€â”€ map_corridor.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ checkpoints/              # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸
â”‚   â”œâ”€â”€ update_50.pth
â”‚   â”œâ”€â”€ update_100.pth
â”‚   â””â”€â”€ final.pth
â”œâ”€â”€ coverage/                 # ì»¤ë²„ë¦¬ì§€ íˆíŠ¸ë§µ
â”‚   â”œâ”€â”€ update_50/
â”‚   â””â”€â”€ update_100/
â”œâ”€â”€ analysis/                 # ë¶„ì„ ê²°ê³¼
â”‚   â”œâ”€â”€ learning_curves.png
â”‚   â”œâ”€â”€ training_diagnostics.png
â”‚   â”œâ”€â”€ map_comparison.png
â”‚   â””â”€â”€ training_report.txt
â”œâ”€â”€ training_config.yaml      # í•™ìŠµ ì„¤ì •
â””â”€â”€ results.json              # ìµœì¢… ê²°ê³¼
```

---

## ğŸ“Š ë¡œê¹… ë ˆë²¨

### 1. **Step-Level** (ë§¤ step)

**íŒŒì¼**: `csv/steps.csv`

**ê¸°ë¡ ë°ì´í„°**:
```
global_step, update, episode, map_name,
action_mode, action_replan_idx,
reward_total, reward_event, reward_patrol, reward_safety, reward_efficiency,
has_event, nav_time, battery_level,
valid_action_count, patrol_valid, dispatch_valid,
collision, nav_success, event_resolved
```

**ìš©ë„**:
- ì„¸ë°€í•œ í–‰ë™ ë¶„ì„
- Reward component ë¶„ì„
- Action masking ê²€ì¦
- ë°°í„°ë¦¬ ì‚¬ìš© íŒ¨í„´

**í¬ê¸°**: ~10MB per 100K steps

---

### 2. **Episode-Level** (ì—í”¼ì†Œë“œ ì¢…ë£Œ ì‹œ)

**íŒŒì¼**: `csv/episodes.csv`

**ê¸°ë¡ ë°ì´í„°**:
```
episode, global_step, map_name,
return, length, duration,
event_success_rate, patrol_coverage, safety_violations,
avg_reward_event, avg_reward_patrol, avg_reward_safety, avg_reward_efficiency,
patrol_ratio, dispatch_ratio,
avg_nav_time, final_battery,
events_detected, events_responded, events_successful
```

**ìš©ë„**:
- í•™ìŠµ ê³¡ì„  í”Œë¡¯
- ì„±ëŠ¥ ì¶”ì„¸ ë¶„ì„
- ì—í”¼ì†Œë“œ í†µê³„

**í¬ê¸°**: ~1MB per 10K episodes

---

### 3. **Update-Level** (PPO ì—…ë°ì´íŠ¸ë§ˆë‹¤)

**íŒŒì¼**: `csv/updates.csv`

**ê¸°ë¡ ë°ì´í„°**:
```
update, global_step,
policy_loss, value_loss, entropy, approx_kl, clipfrac, explained_variance,
entropy_coef, learning_rate,
advantage_mean, advantage_std, advantage_min, advantage_max,
value_mean, return_mean, value_return_gap,
reward_raw_mean, reward_raw_std, reward_normalized_mean, reward_normalized_std,
grad_norm, fps
```

**ìš©ë„**:
- PPO ì•Œê³ ë¦¬ì¦˜ ì§„ë‹¨
- Policy collapse ê°ì§€
- Critic ì„±ëŠ¥ í‰ê°€
- Hyperparameter ì˜í–¥ ë¶„ì„

**í¬ê¸°**: ~100KB per 2K updates

---

### 4. **Map-Level** (ë§µë³„ ì—í”¼ì†Œë“œ)

**íŒŒì¼**: `csv/map_{name}.csv`

**ê¸°ë¡ ë°ì´í„°**:
```
episode, global_step,
return, length,
event_success_rate, patrol_coverage,
patrol_ratio, dispatch_ratio
```

**ìš©ë„**:
- ë§µë³„ ì„±ëŠ¥ ë¹„êµ
- ì¼ë°˜í™” ëŠ¥ë ¥ í‰ê°€
- ë§µ ë‚œì´ë„ ë¶„ì„

**í¬ê¸°**: ~100KB per map

---

## ğŸš€ ì‚¬ìš©ë²•

### 1ë‹¨ê³„: í•™ìŠµ ì‹œì‘
```bash
python scripts/train_with_logging.py \
    --total-timesteps 5000000 \
    --seed 42 \
    --cuda \
    --experiment-name my_experiment
```

**ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**:
```bash
# ë³„ë„ í„°ë¯¸ë„
tensorboard --logdir runs/my_experiment
# http://localhost:6006
```

---

### 2ë‹¨ê³„: í•™ìŠµ ì¤‘ í™•ì¸

**TensorBoardì—ì„œ ì‹¤ì‹œê°„ í™•ì¸**:
- `episode/return` - ë¦¬í„´ ì¶”ì„¸
- `episode/event_success_rate` - ì„±ê³µë¥ 
- `train/entropy` - íƒìƒ‰ ìƒíƒœ
- `train/value_loss` - Critic í•™ìŠµ
- `diagnostics/*` - ìƒì„¸ ì§„ë‹¨

**Console ì¶œë ¥**:
```
Update 100/2441 (Step 204,800):
  FPS: 1234.5
  Entropy coef: 0.0959

  Per-Map Performance:
    map_large_square: Return=523.4Â±45.2, Success=87.3%, Cov=94.2%
    map_office_building: Return=-234.1Â±67.8, Success=72.1%, Cov=88.6%
    ...

  Training:
    policy_loss: 0.0012
    value_loss: 12345.67
    entropy: 0.0456
    approx_kl: 0.0123
    explained_variance: 0.7890
```

---

### 3ë‹¨ê³„: í•™ìŠµ í›„ ë¶„ì„

```bash
# ë¡œê·¸ ë¶„ì„ ë° í”Œë¡¯ ìƒì„±
python scripts/analyze_logs.py runs/my_experiment/20251230-123456

# ì¶œë ¥:
# âœ… Loaded 15234 episodes
# âœ… Loaded 2441 updates
# âœ… Loaded 5000000 steps
# âœ… Loaded map: map_large_square (2534 episodes)
# ...
# âœ… Saved: runs/.../analysis/learning_curves.png
# âœ… Saved: runs/.../analysis/training_diagnostics.png
# âœ… Saved: runs/.../analysis/map_comparison.png
# âœ… Saved: runs/.../analysis/training_report.txt
```

---

## ğŸ“ˆ ìƒì„±ë˜ëŠ” í”Œë¡¯

### 1. **learning_curves.png**

6ê°œ ì„œë¸Œí”Œë¡¯:
1. **Episode Return** - í•™ìŠµ ì§„í–‰ ìƒí™©
2. **Event Success Rate** - ì´ë²¤íŠ¸ ëŒ€ì‘ ì„±ëŠ¥
3. **Patrol Coverage** - ìˆœì°° ì»¤ë²„ë¦¬ì§€
4. **Action Distribution** - Patrol/Dispatch ë¹„ìœ¨
5. **Episode Length** - ì—í”¼ì†Œë“œ ê¸¸ì´
6. **Safety Violations** - ì•ˆì „ ìœ„ë°˜ ì¶”ì„¸

**í•´ì„**:
- Returnì´ ìƒìŠ¹ â†’ í•™ìŠµ ì„±ê³µ
- Success rate > 75% â†’ ëª©í‘œ ë‹¬ì„±
- Coverage > 80% â†’ ìˆœì°° íš¨ìœ¨ì 
- Action distribution ê· í˜• â†’ ì •ìƒ í•™ìŠµ

---

### 2. **training_diagnostics.png**

6ê°œ PPO ì§„ë‹¨ í”Œë¡¯:
1. **Entropy** - íƒìƒ‰ vs exploitation
2. **Approx KL** - ì •ì±… ë³€í™” í¬ê¸°
3. **Value Loss** - Critic í•™ìŠµ ìƒíƒœ
4. **Explained Variance** - Critic ì„±ëŠ¥
5. **Policy Loss** - Actor í•™ìŠµ ìƒíƒœ
6. **Clipfrac** - PPO clipping ì‘ë™

**ê²½ê³  ì‹ í˜¸**:
- âŒ Entropy < 0.02 â†’ Policy collapse
- âŒ Approx KL â‰ˆ 0 â†’ ì •ì±… ì—…ë°ì´íŠ¸ ë©ˆì¶¤
- âŒ Value Loss > 100K â†’ Critic í­ì£¼
- âŒ Explained Var < 0.1 â†’ Critic ë¶€ì •í™•
- âŒ Clipfrac < 0.05 â†’ PPO ì‘ë™ ì•ˆ í•¨

---

### 3. **map_comparison.png**

4ê°œ ë§µë³„ ë¹„êµ í”Œë¡¯:
1. **Average Return** - ë§µë³„ í‰ê·  ë¦¬í„´
2. **Success Rate** - ë§µë³„ ì„±ê³µë¥ 
3. **Coverage** - ë§µë³„ ì»¤ë²„ë¦¬ì§€
4. **Learning Curves** - ë§µë³„ í•™ìŠµ ê³¡ì„ 

**í•´ì„**:
- ëª¨ë“  ë§µì—ì„œ ì–‘ìˆ˜ ë¦¬í„´ â†’ ì¼ë°˜í™” ì„±ê³µ
- ë§µ ê°„ ì„±ëŠ¥ ì°¨ì´ ì‘ìŒ â†’ ê· í˜• í•™ìŠµ
- ì–´ë ¤ìš´ ë§µ ì„±ëŠ¥ ë‚®ìŒ â†’ ì •ìƒ (expected)

---

### 4. **training_report.txt**

í…ìŠ¤íŠ¸ ìš”ì•½:
```
================================================================================
í•™ìŠµ ê²°ê³¼ ë¦¬í¬íŠ¸
================================================================================

í•™ìŠµ ì‹œê°„: 2.45 hours
ì´ Steps: 5,000,000
ì´ Updates: 2,441

================================================================================
ì „ì²´ ì„±ëŠ¥ (ìµœê·¼ 100 ì—í”¼ì†Œë“œ)
================================================================================
  í‰ê·  Return: 1234.56 Â± 456.78
  Event Success Rate: 78.9%
  Patrol Coverage: 85.3%
  Safety Violations: 0.12 per episode
  Patrol Ratio: 67.8%
  Dispatch Ratio: 32.2%

================================================================================
ë§µë³„ ì„±ëŠ¥ (ìµœê·¼ 100 ì—í”¼ì†Œë“œ)
================================================================================

map_large_square:
  Episodes: 2534
  Return: 1523.4 Â± 345.2
  Success: 87.3%
  Coverage: 94.2%

...

================================================================================
í•™ìŠµ ìƒíƒœ ì§„ë‹¨ (ìµœê·¼ 100 updates)
================================================================================
  Entropy: 0.034567 (healthy: > 0.02)
  Approx KL: 0.012345 (healthy: > 0.001)
  Value Loss: 45678.90 (healthy: < 100K)
  Explained Variance: 0.6789 (good: > 0.5)
  Clipfrac: 0.1234 (healthy: > 0.05)

âš ï¸  ê²½ê³  ì‚¬í•­:
  ì—†ìŒ - í•™ìŠµ ì •ìƒ ì§„í–‰ ì¤‘ âœ…
```

---

## ğŸ” ë¬¸ì œ ì§„ë‹¨ ê°€ì´ë“œ

### Case 1: Policy Collapse

**ì¦ìƒ**:
- Entropy < 0.02
- Approx KL â‰ˆ 0
- Success rate í•˜ë½

**í™•ì¸**:
```bash
# updates.csv í™•ì¸
python -c "
import pandas as pd
df = pd.read_csv('runs/.../csv/updates.csv')
print('Recent entropy:', df['entropy'].tail(100).mean())
print('Recent approx_kl:', df['approx_kl'].tail(100).mean())
"
```

**í•´ê²°**:
- Entropy coefficient ì¦ê°€ (0.1 â†’ 0.15)
- Learning rate ê°ì†Œ
- `POLICY_COLLAPSE_FIX.md` ì°¸ê³ 

---

### Case 2: Value Loss Explosion

**ì¦ìƒ**:
- Value loss > 100K
- Explained variance < 0.1
- í•™ìŠµ ë¶ˆì•ˆì •

**í™•ì¸**:
```bash
# updates.csv í™•ì¸
python -c "
import pandas as pd
df = pd.read_csv('runs/.../csv/updates.csv')
print('Recent value_loss:', df['value_loss'].tail(100).mean())
print('Recent explained_var:', df['explained_variance'].tail(100).mean())
"
```

**í•´ê²°**:
- Reward normalization í™•ì¸
- Clip rewards ê°ì†Œ (5.0 â†’ 3.0)
- Value loss coefficient ì¦ê°€ (1.0 â†’ 2.0)

---

### Case 3: Invalid Action ë§ìŒ

**ì¦ìƒ**:
- Console warning í­ë°œ
- Patrol ratio 100%
- Dispatch ratio 0%

**í™•ì¸**:
```bash
# steps.csv í™•ì¸
python -c "
import pandas as pd
df = pd.read_csv('runs/.../csv/steps.csv')
print('Avg valid actions:', df['valid_action_count'].mean())
print('Dispatch valid rate:', df['dispatch_valid'].mean())
"
```

**í•´ê²°**:
- Action masking ì ìš© í™•ì¸
- `ACTION_MASKING_FIX.md` ì°¸ê³ 

---

## ğŸ’¾ ë°ì´í„° í¬ê¸° ì˜ˆìƒ

| ë°ì´í„° | 5M steps | 10M steps |
|--------|----------|-----------|
| steps.csv | ~500MB | ~1GB |
| episodes.csv | ~5MB | ~10MB |
| updates.csv | ~250KB | ~500KB |
| map CSVs (6ê°œ) | ~3MB | ~6MB |
| **Total CSV** | **~508MB** | **~1.02GB** |
| TensorBoard | ~100MB | ~200MB |
| **Total** | **~608MB** | **~1.22GB** |

**ë””ìŠ¤í¬ ê³µê°„**: ìµœì†Œ 2GB ì—¬ìœ  ê¶Œì¥

---

## ğŸ¯ Best Practices

### 1. **í•­ìƒ TensorBoard ì‹¤í–‰**
```bash
# í•™ìŠµ ì „ì— ë¯¸ë¦¬ ì‹¤í–‰
tensorboard --logdir runs --port 6006
```

### 2. **ì •ê¸°ì ìœ¼ë¡œ analyze_logs ì‹¤í–‰**
```bash
# 100K stepsë§ˆë‹¤
python scripts/analyze_logs.py runs/my_experiment/20251230-123456
```

### 3. **Checkpoint ì£¼ê¸°ì  ë°±ì—…**
```bash
# ì¤‘ìš”í•œ checkpoint ë°±ì—…
cp runs/.../checkpoints/update_500.pth backups/
```

### 4. **CSV íŒŒì¼ ì••ì¶• ë³´ê´€**
```bash
# í•™ìŠµ ì™„ë£Œ í›„
cd runs/my_experiment/20251230-123456
tar -czf logs.tar.gz csv/
```

---

## ğŸ“Š TensorBoard ì£¼ìš” Metrics

### ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ (í•„ìˆ˜)

| Metric | ìœ„ì¹˜ | ì •ìƒ ë²”ìœ„ | ê²½ê³  |
|--------|------|----------|------|
| **Entropy** | `train/entropy` | 0.03-0.10 | < 0.02 |
| **Approx KL** | `train/approx_kl` | 0.001-0.02 | < 0.001 |
| **Value Loss** | `train/value_loss` | < 100K | > 100K |
| **Success Rate** | `episode/event_success_rate` | ì¦ê°€ ì¶”ì„¸ | í•˜ë½ |
| **Return** | `episode/return` | ì¦ê°€ ì¶”ì„¸ | í•˜ë½ |

### ì§„ë‹¨ìš© (ì£¼ê¸°ì  í™•ì¸)

| Metric | ìœ„ì¹˜ | ì˜ë¯¸ |
|--------|------|------|
| **Explained Variance** | `train/explained_variance` | Critic ì„±ëŠ¥ |
| **Clipfrac** | `train/clipfrac` | PPO ì‘ë™ |
| **Patrol Ratio** | `episode/patrol_ratio` | í–‰ë™ ë¶„í¬ |
| **Valid Actions** | `diagnostics/valid_action_count_mean` | Masking ì‘ë™ |
| **Reward Components** | `step/{map}/reward` | Reward ë¶„í•´ |

---

## ğŸ”§ ì»¤ìŠ¤í„°ë§ˆì´ì§•

### ì¶”ê°€ Metric ë¡œê¹…

`train_with_logging.py` ìˆ˜ì •:

```python
# Step-levelì— ìƒˆ metric ì¶”ê°€
step_data['my_custom_metric'] = calculate_custom_metric()

# TensorBoardì— ë¡œê¹…
self.writer.add_scalar("custom/my_metric", value, global_step)

# CSVì— ì¶”ê°€ (header ë¨¼ì € ìˆ˜ì •)
self.step_writer.writerow([..., step_data['my_custom_metric']])
```

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

í•™ìŠµ ì‹œì‘ ì „:
- [ ] `tensorboard --logdir runs` ì‹¤í–‰
- [ ] ë””ìŠ¤í¬ ê³µê°„ 2GB+ í™•ë³´
- [ ] Experiment name ì„¤ì •

í•™ìŠµ ì¤‘ (ë§¤ 100K steps):
- [ ] TensorBoardì—ì„œ entropy í™•ì¸ (> 0.02)
- [ ] Value loss í™•ì¸ (< 100K)
- [ ] Success rate ì¶”ì„¸ í™•ì¸
- [ ] Console warning í™•ì¸ (ì—†ì–´ì•¼ í•¨)

í•™ìŠµ í›„:
- [ ] `analyze_logs.py` ì‹¤í–‰
- [ ] `training_report.txt` ì½ê¸°
- [ ] í”Œë¡¯ í™•ì¸ (learning_curves.png ë“±)
- [ ] ì¤‘ìš” checkpoint ë°±ì—…

---

## ğŸ“ ë¬¸ì œ í•´ê²°

### CSV íŒŒì¼ì´ ë„ˆë¬´ í¼
```bash
# Step CSV ìƒ˜í”Œë§ (ë§¤ Në²ˆì§¸ stepë§Œ)
python -c "
import pandas as pd
df = pd.read_csv('steps.csv')
df_sampled = df.iloc[::100]  # 100 stepë§ˆë‹¤
df_sampled.to_csv('steps_sampled.csv', index=False)
"
```

### TensorBoardê°€ ëŠë¦¼
```bash
# íŠ¹ì • runë§Œ ë¡œë“œ
tensorboard --logdir runs/my_experiment/20251230-123456
```

### ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ ì—ëŸ¬
```bash
# Matplotlib ì„¤ì¹˜
pip install matplotlib pandas

# ë‹¤ì‹œ ì‹¤í–‰
python scripts/analyze_logs.py runs/.../
```

---

**ì‘ì„±ì**: Reviewer ë°•ìš©ì¤€
**ìµœì¢… ìˆ˜ì •**: 2025-12-30
**ë²„ì „**: 1.0
