"""
Type definitions and data structures for the RL Dispatch system.

This module defines all the core types used throughout the system, including:
- Robot state representation
- Event and patrol point structures
- Action space components
- Observation vectors
- Metrics and logging structures

All types use dataclasses for immutability and type safety, with comprehensive
documentation for maintainability and collaboration.
"""

from dataclasses import dataclass, field
from enum import IntEnum
from typing import List, Optional, Tuple
import numpy as np
import numpy.typing as npt


class ActionMode(IntEnum):
    """
    Action mode for the dispatch decision.

    This binary decision determines whether the robot should continue its
    current patrol route or dispatch to respond to a detected event.

    Attributes:
        PATROL (0): Continue following the current patrol route
        DISPATCH (1): Interrupt patrol to respond to the detected event

    Example:
        >>> mode = ActionMode.DISPATCH
        >>> if mode == ActionMode.DISPATCH:
        ...     print("Robot will respond to event")
    """
    PATROL = 0
    DISPATCH = 1


@dataclass(frozen=True)
class PatrolPoint:
    """
    Represents a single waypoint in the patrol route.

    Each patrol point has a 2D position and metadata about when it was last
    visited and its priority. The patrol route is composed of multiple points
    that the robot visits in sequence.

    Attributes:
        x: X-coordinate in meters (map frame)
        y: Y-coordinate in meters (map frame)
        last_visit_time: Timestamp of last visit (seconds since episode start)
        priority: Priority weight for coverage calculation (0.0-1.0, higher is more important)
        point_id: Unique identifier for this patrol point

    Example:
        >>> point = PatrolPoint(x=10.5, y=5.2, last_visit_time=0.0, priority=1.0, point_id=0)
        >>> position = (point.x, point.y)
    """
    x: float
    y: float
    last_visit_time: float = 0.0
    priority: float = 1.0
    point_id: int = 0

    @property
    def position(self) -> Tuple[float, float]:
        """Returns the (x, y) position as a tuple."""
        return (self.x, self.y)

    def distance_to(self, other: 'PatrolPoint') -> float:
        """
        Calculate Euclidean distance to another patrol point.

        Args:
            other: Another PatrolPoint instance

        Returns:
            Euclidean distance in meters
        """
        return np.sqrt((self.x - other.x)**2 + (self.y - other.y)**2)

    def time_since_visit(self, current_time: float) -> float:
        """
        Calculate time elapsed since last visit.

        Args:
            current_time: Current episode time in seconds

        Returns:
            Time elapsed in seconds
        """
        return current_time - self.last_visit_time


@dataclass(frozen=True)
class Event:
    """
    Represents a detected event from the CCTV system.

    Events are generated by CCTV monitoring and may require robot investigation.
    Each event has spatial location, temporal information, and confidence metrics.

    Attributes:
        x: X-coordinate in meters (map frame)
        y: Y-coordinate in meters (map frame)
        urgency: Urgency level (0.0-1.0, higher is more urgent)
        confidence: Detection confidence (0.0-1.0, from CCTV classifier)
        detection_time: When event was first detected (seconds since episode start)
        event_id: Unique identifier for this event
        is_active: Whether this event is still unresolved

    Note:
        Urgency is typically determined by the CCTV system based on event type
        (e.g., intrusion=1.0, loitering=0.5, normal=0.1). Confidence reflects
        the classifier's certainty in the detection.

    Example:
        >>> event = Event(
        ...     x=20.0, y=15.0,
        ...     urgency=0.8,
        ...     confidence=0.95,
        ...     detection_time=100.0,
        ...     event_id=1
        ... )
        >>> if event.urgency > 0.7 and event.confidence > 0.9:
        ...     print("High priority event requiring immediate response")
    """
    x: float
    y: float
    urgency: float
    confidence: float
    detection_time: float
    event_id: int
    is_active: bool = True

    @property
    def position(self) -> Tuple[float, float]:
        """Returns the (x, y) position as a tuple."""
        return (self.x, self.y)

    def time_elapsed(self, current_time: float) -> float:
        """
        Calculate time elapsed since event detection.

        Args:
            current_time: Current episode time in seconds

        Returns:
            Time elapsed in seconds
        """
        return current_time - self.detection_time

    def distance_to(self, x: float, y: float) -> float:
        """
        Calculate Euclidean distance from event to a position.

        Args:
            x: Target x-coordinate
            y: Target y-coordinate

        Returns:
            Euclidean distance in meters
        """
        return np.sqrt((self.x - x)**2 + (self.y - y)**2)


@dataclass(frozen=True)
class RobotState:
    """
    Complete state representation of the robot.

    Encapsulates all physical state information about the robot including
    pose, velocity, battery, and current navigation goal.

    Attributes:
        x: X-coordinate in meters (map frame)
        y: Y-coordinate in meters (map frame)
        heading: Orientation in radians (0 = east, counter-clockwise)
        velocity: Linear velocity in m/s
        angular_velocity: Angular velocity in rad/s
        battery_level: Battery state of charge (0.0-1.0)
        current_goal_idx: Index of current patrol point being navigated to (-1 if none)

    Example:
        >>> robot = RobotState(
        ...     x=5.0, y=3.0, heading=1.57,  # heading ~90deg (north)
        ...     velocity=0.5, angular_velocity=0.0,
        ...     battery_level=0.8,
        ...     current_goal_idx=2
        ... )
        >>> print(f"Robot at ({robot.x:.1f}, {robot.y:.1f}), heading {np.degrees(robot.heading):.0f}°")
    """
    x: float
    y: float
    heading: float  # radians
    velocity: float  # m/s
    angular_velocity: float  # rad/s
    battery_level: float  # 0.0 to 1.0
    current_goal_idx: int = -1  # -1 if no goal

    @property
    def position(self) -> Tuple[float, float]:
        """Returns the (x, y) position as a tuple."""
        return (self.x, self.y)

    @property
    def heading_vector(self) -> Tuple[float, float]:
        """
        Returns the heading as a unit direction vector.

        Returns:
            (cos(heading), sin(heading)) unit vector
        """
        return (np.cos(self.heading), np.sin(self.heading))


@dataclass(frozen=True)
class Candidate:
    """
    Represents a candidate patrol route replan strategy.

    Each candidate is a complete patrol route ordering generated by a specific
    heuristic strategy (e.g., nearest-first, most-overdue-first). The RL policy
    selects one candidate to execute.

    Attributes:
        patrol_order: Ordered list of patrol point indices to visit
        estimated_total_distance: Total route distance in meters (approximate)
        max_coverage_gap: Maximum time gap for any patrol point (seconds)
        strategy_name: Name of the generation heuristic (e.g., "nearest_first")
        strategy_id: Unique integer ID for this strategy

    Note:
        The candidate-based action space reduces the combinatorial explosion
        from M! (all permutations) to K (number of strategies, typically 6).
        This makes the action space tractable while maintaining solution quality.

    Example:
        >>> candidate = Candidate(
        ...     patrol_order=[2, 0, 3, 1],
        ...     estimated_total_distance=45.3,
        ...     max_coverage_gap=120.0,
        ...     strategy_name="nearest_first",
        ...     strategy_id=1
        ... )
        >>> print(f"Strategy '{candidate.strategy_name}' route: {candidate.patrol_order}")
    """
    patrol_order: Tuple[int, ...]  # Immutable sequence of patrol point indices
    estimated_total_distance: float
    max_coverage_gap: float
    strategy_name: str
    strategy_id: int

    @property
    def num_points(self) -> int:
        """Returns the number of patrol points in this route."""
        return len(self.patrol_order)


@dataclass(frozen=True)
class Action:
    """
    Complete action taken by the RL policy.

    Represents the composite action space: a binary dispatch decision combined
    with a categorical replan strategy selection.

    Attributes:
        mode: Dispatch decision (PATROL=0 or DISPATCH=1)
        replan_idx: Index of selected candidate strategy (0 to K-1)

    Note:
        Action masking may restrict valid actions based on state:
        - If no event exists, DISPATCH mode is masked out
        - If battery is critically low, DISPATCH may be masked
        - If robot is already dispatching, mode may be locked

    Example:
        >>> action = Action(mode=ActionMode.DISPATCH, replan_idx=2)
        >>> if action.mode == ActionMode.DISPATCH:
        ...     print(f"Dispatching with strategy {action.replan_idx}")
    """
    mode: ActionMode
    replan_idx: int

    def to_tuple(self) -> Tuple[int, int]:
        """
        Convert action to integer tuple for compatibility.

        Returns:
            (mode_int, replan_idx) tuple
        """
        return (int(self.mode), self.replan_idx)

    @classmethod
    def from_tuple(cls, action_tuple: Tuple[int, int]) -> 'Action':
        """
        Create Action from integer tuple.

        Args:
            action_tuple: (mode_int, replan_idx) tuple

        Returns:
            Action instance
        """
        return cls(mode=ActionMode(action_tuple[0]), replan_idx=action_tuple[1])


@dataclass(frozen=True)
class State:
    """
    Complete environment state at a given timestep.

    Aggregates all state information including robot, patrol route, current event,
    and available replan candidates. This is the full MDP state (not the observation).

    Attributes:
        robot: Current robot state
        patrol_points: List of all patrol points with visit times
        current_event: Active event if any (None otherwise)
        current_time: Current episode time in seconds
        candidates: Available replan candidates for this state
        lidar_ranges: Raw LiDAR range measurements (64 channels)

    Note:
        The State contains full ground truth information. The Observation
        is a processed, normalized vector derived from the State.

    Example:
        >>> state = State(
        ...     robot=robot_state,
        ...     patrol_points=patrol_points,
        ...     current_event=event,
        ...     current_time=150.0,
        ...     candidates=candidates,
        ...     lidar_ranges=lidar_data
        ... )
    """
    robot: RobotState
    patrol_points: Tuple[PatrolPoint, ...]
    current_event: Optional[Event]
    current_time: float
    candidates: Tuple[Candidate, ...]
    lidar_ranges: npt.NDArray[np.float32]  # Shape: (64,)

    @property
    def has_event(self) -> bool:
        """Returns True if there is an active event."""
        return self.current_event is not None and self.current_event.is_active

    @property
    def num_patrol_points(self) -> int:
        """Returns the number of patrol points."""
        return len(self.patrol_points)

    @property
    def num_candidates(self) -> int:
        """Returns the number of available candidates."""
        return len(self.candidates)


@dataclass(frozen=True)
class Observation:
    """
    Normalized observation vector for the RL policy.

    Reviewer 박용준: Phase 4 - Enhanced to 88-dimensional observation.
    All values are normalized to approximately [-1, 1] or [0, 1] ranges.

    Observation Components (88D total - Phase 4 Enhanced):
        - goal_relative_vec (2D): Normalized (dx, dy) to current goal
        - heading_sin_cos (2D): (sin(theta), cos(theta)) of robot heading
        - velocity_angular (2D): Normalized (v, omega)
        - battery (1D): Battery level [0, 1]
        - lidar_ranges (64D): Normalized LiDAR ranges
        - event_features (4D): [exists, urgency, confidence, elapsed_time_norm]
        - patrol_features (2D): [distance_to_next_norm, coverage_gap_ratio]
        - event_risk_level (1D): Event risk [0, 1] (Phase 4)
        - patrol_crisis (3D): [max_gap, critical_count, crisis_score] (Phase 4)
        - candidate_feasibility (6D): Feasibility per candidate (Phase 4)
        - urgency_risk_combined (1D): Combined priority signal (Phase 4)

    Note:
        Normalization is critical for RL training stability. Running statistics
        (mean/std) are maintained during training and applied at inference.

    Example:
        >>> obs = Observation(vector=np.zeros(88, dtype=np.float32))
        >>> assert obs.vector.shape == (88,)
        >>> assert obs.dim == 88
    """
    vector: npt.NDArray[np.float32]  # Shape: (88,) - Reviewer 박용준: Phase 4

    def __post_init__(self) -> None:
        """Validate observation dimensions."""
        if self.vector.shape != (88,):  # Reviewer 박용준: Phase 4 - 77 → 88
            raise ValueError(f"Observation must be 88D, got {self.vector.shape}")

    @property
    def dim(self) -> int:
        """Returns the observation dimensionality."""
        return 88  # Reviewer 박용준: Phase 4 - 77 → 88

    def to_dict(self) -> dict:
        """
        Convert observation to dictionary with named components.

        Returns:
            Dictionary with keys: goal_rel, heading, velocity, battery,
            lidar, event, patrol, event_risk, patrol_crisis,
            candidate_feasibility, urgency_risk_combined (Phase 4)
        """
        return {
            "goal_relative": self.vector[0:2],
            "heading_sin_cos": self.vector[2:4],
            "velocity_angular": self.vector[4:6],
            "battery": self.vector[6:7],
            "lidar": self.vector[7:71],
            "event_features": self.vector[71:75],
            "patrol_features": self.vector[75:77],
            # Reviewer 박용준: Phase 4 enhancements
            "event_risk_level": self.vector[77:78],
            "patrol_crisis": self.vector[78:81],
            "candidate_feasibility": self.vector[81:87],
            "urgency_risk_combined": self.vector[87:88],
        }


@dataclass
class RewardComponents:
    """
    Breakdown of multi-component reward calculation.

    The total reward is a weighted sum of four components. This structure
    allows for detailed logging and ablation studies.

    Attributes:
        event: Reward from event response (R^evt)
        patrol: Reward from patrol coverage (R^pat)
        safety: Reward from collision avoidance (R^safe)
        efficiency: Reward from path efficiency (R^eff)
        total: Weighted sum of all components

    Note:
        Typical weights: w_evt=1.0, w_pat=0.5, w_safe=2.0, w_eff=0.1
        These are configurable and should be tuned via ablation studies.

    Example:
        >>> rewards = RewardComponents(
        ...     event=10.0,  # Successfully responded to event
        ...     patrol=-5.0,  # But created coverage gap
        ...     safety=0.0,  # No collisions
        ...     efficiency=-2.0,  # Longer path taken
        ...     total=3.0  # Net positive reward
        ... )
    """
    event: float = 0.0
    patrol: float = 0.0
    safety: float = 0.0
    efficiency: float = 0.0
    total: float = 0.0

    def compute_total(self, weights: 'RewardConfig') -> float:
        """
        Compute weighted sum of reward components.

        Args:
            weights: RewardConfig with component weights

        Returns:
            Total weighted reward
        """
        self.total = (
            weights.w_event * self.event +
            weights.w_patrol * self.patrol +
            weights.w_safety * self.safety +
            weights.w_efficiency * self.efficiency
        )
        return self.total


@dataclass
class EpisodeMetrics:
    """
    Aggregated metrics for a complete episode.

    Used for logging, evaluation, and comparison with baseline policies.

    Attributes:
        episode_return: Cumulative discounted return
        episode_length: Number of steps (SMDP steps, not simulation timesteps)
        events_detected: Total events generated in episode
        events_responded: Number of events robot responded to
        events_successful: Number of successful event resolutions
        avg_event_delay: Average time from detection to response (seconds)
        patrol_coverage_ratio: Fraction of patrol points visited on schedule
        safety_violations: Number of collisions or Nav2 failures
        total_distance: Total distance traveled (meters)
        final_battery: Battery level at episode end

    Example:
        >>> metrics = EpisodeMetrics(
        ...     episode_return=234.5,
        ...     episode_length=87,
        ...     events_detected=5,
        ...     events_responded=4,
        ...     events_successful=3,
        ...     avg_event_delay=25.3
        ... )
        >>> success_rate = metrics.events_successful / metrics.events_detected
    """
    episode_return: float = 0.0
    episode_length: int = 0
    events_detected: int = 0
    events_responded: int = 0
    events_successful: int = 0
    avg_event_delay: float = 0.0
    patrol_coverage_ratio: float = 0.0
    safety_violations: int = 0
    total_distance: float = 0.0
    final_battery: float = 1.0

    @property
    def event_response_rate(self) -> float:
        """Fraction of events that were responded to."""
        return self.events_responded / max(self.events_detected, 1)

    @property
    def event_success_rate(self) -> float:
        """Fraction of events successfully resolved."""
        return self.events_successful / max(self.events_detected, 1)
